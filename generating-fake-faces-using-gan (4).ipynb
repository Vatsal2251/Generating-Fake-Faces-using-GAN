{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1328233,"sourceType":"datasetVersion","datasetId":770718}],"dockerImageVersionId":30056,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Creating Realistic Human Faces with Generative Adversarial Networks\n\nThis project has successfully developed a sophisticated GAN model, specifically using DCGAN architecture, to generate highly realistic synthetic human faces. By addressing challenges like mode collapse and training instability, the project achieved significant improvements in image quality, contributing valuable methodologies and insights to the fields of entertainment, security, and AI training.","metadata":{}},{"cell_type":"markdown","source":"## Importing necessary libraries","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nimport keras \nimport keras.backend as K\nfrom keras import layers\nfrom keras.applications.inception_v3 import InceptionV3, preprocess_input\nfrom keras.models import Model\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport cv2\nimport os\nfrom tqdm import tqdm\nimport re\nfrom keras.preprocessing.image import img_to_array\nfrom scipy.linalg import sqrtm\nfrom skimage.transform import resize","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-21T20:37:05.603233Z","iopub.execute_input":"2024-06-21T20:37:05.603763Z","iopub.status.idle":"2024-06-21T20:37:11.337938Z","shell.execute_reply.started":"2024-06-21T20:37:05.603633Z","shell.execute_reply":"2024-06-21T20:37:11.337118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Loading data\n","metadata":{}},{"cell_type":"code","source":"# getting the files in proper order\ndef sort_alphanumeric(data):  \n    convert = lambda text: int(text) if text.isdigit() else text.lower()\n    alphanum_key = lambda key: [convert(c) for c in re.split('([0-9]+)',key)]\n    return sorted(data,key = alphanum_key)\n\nSIZE = 128\nimages = []\npath = '../input/face-mask-lite-dataset/without_mask'\nfiles = os.listdir(path)\nfiles = sort_alphanumeric(files)\nfor i in tqdm(files):           \n    img = cv2.imread(path + '/'+i,1)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    img = cv2.resize(img, (SIZE, SIZE))\n    img = (img - 127.5) / 127.5\n    img = img.astype(float)\n    images.append(img_to_array(img))","metadata":{"execution":{"iopub.status.busy":"2024-06-21T20:37:11.339762Z","iopub.execute_input":"2024-06-21T20:37:11.340084Z","iopub.status.idle":"2024-06-21T20:47:34.329279Z","shell.execute_reply.started":"2024-06-21T20:37:11.340055Z","shell.execute_reply":"2024-06-21T20:47:34.328487Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Visualizing real images","metadata":{}},{"cell_type":"code","source":"def plot_img(sqr = 5):\n    plt.figure(figsize = (10,10))\n    plt.title(\"Real Images\",fontsize = 35)\n    for i in range(sqr * sqr):\n        plt.subplot(sqr,sqr,i+1)\n        plt.imshow(images[i]*0.5 + 0.5 )\n        plt.xticks([])\n        plt.yticks([])\n\nplot_img(6)\n    ","metadata":{"execution":{"iopub.status.busy":"2024-06-21T20:47:34.330453Z","iopub.execute_input":"2024-06-21T20:47:34.330731Z","iopub.status.idle":"2024-06-21T20:47:35.973898Z","shell.execute_reply.started":"2024-06-21T20:47:34.330705Z","shell.execute_reply":"2024-06-21T20:47:35.972778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dividing the dataset into batches","metadata":{}},{"cell_type":"code","source":"batch_size = 32\ndataset=tf.data.Dataset.from_tensor_slices(np.array(images)).batch(batch_size)","metadata":{"execution":{"iopub.status.busy":"2024-06-21T20:47:35.975155Z","iopub.execute_input":"2024-06-21T20:47:35.975492Z","iopub.status.idle":"2024-06-21T20:47:40.022908Z","shell.execute_reply.started":"2024-06-21T20:47:35.975459Z","shell.execute_reply":"2024-06-21T20:47:40.022150Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Generator model","metadata":{}},{"cell_type":"code","source":"latent_dim = 100\ndef Generator():\n    model = tf.keras.Sequential()\n    model.add(layers.Dense(128*128*3, use_bias=False, input_shape=(latent_dim,)))\n    model.add(layers.Reshape((128,128,3)))\n    model.add(tf.keras.layers.Conv2D(128,4, strides=1, padding='same',kernel_initializer='he_normal', use_bias=False))\n    model.add(tf.keras.layers.Conv2D(128,4, strides=2, padding='same',kernel_initializer='he_normal', use_bias=False))\n    model.add(tf.keras.layers.BatchNormalization())\n    model.add(tf.keras.layers.LeakyReLU())\n    model.add(tf.keras.layers.Conv2D(256,4, strides=1, padding='same',kernel_initializer='he_normal', use_bias=False))\n    model.add(tf.keras.layers.Conv2D(256,4, strides=2, padding='same',kernel_initializer='he_normal', use_bias=False))\n    model.add(tf.keras.layers.BatchNormalization())\n    model.add(tf.keras.layers.LeakyReLU())\n    model.add(tf.keras.layers.Conv2DTranspose(512, 4, strides=1,padding='same',kernel_initializer='he_normal',use_bias=False))\n    model.add(tf.keras.layers.Conv2D(512,4, strides=2, padding='same',kernel_initializer='he_normal', use_bias=False))\n    model.add(tf.keras.layers.LeakyReLU())\n    model.add(tf.keras.layers.Conv2DTranspose(512, 4, strides=1,padding='same',kernel_initializer='he_normal',use_bias=False))\n    model.add(tf.keras.layers.Conv2DTranspose(512, 4, strides=2,padding='same',kernel_initializer='he_normal',use_bias=False))\n    model.add(tf.keras.layers.BatchNormalization())\n    model.add(tf.keras.layers.LeakyReLU())\n    model.add(tf.keras.layers.Conv2DTranspose(256, 4, strides=1,padding='same',kernel_initializer='he_normal',use_bias=False))\n    model.add(tf.keras.layers.Conv2DTranspose(256, 4, strides=2,padding='same',kernel_initializer='he_normal',use_bias=False))\n    model.add(tf.keras.layers.BatchNormalization())\n    \n    model.add(tf.keras.layers.Conv2DTranspose(128, 4, strides=2,padding='same',kernel_initializer='he_normal',use_bias=False))\n    model.add(tf.keras.layers.Conv2DTranspose(128, 4, strides=1,padding='same',kernel_initializer='he_normal',use_bias=False))\n    model.add(tf.keras.layers.BatchNormalization())\n    model.add(tf.keras.layers.Conv2DTranspose(3,4,strides = 1, padding = 'same',activation = 'tanh'))\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2024-06-21T20:47:40.025580Z","iopub.execute_input":"2024-06-21T20:47:40.025895Z","iopub.status.idle":"2024-06-21T20:47:40.043198Z","shell.execute_reply.started":"2024-06-21T20:47:40.025868Z","shell.execute_reply":"2024-06-21T20:47:40.042436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"generator = Generator()\ngenerator.summary()","metadata":{"execution":{"iopub.status.busy":"2024-06-21T20:47:40.045676Z","iopub.execute_input":"2024-06-21T20:47:40.046006Z","iopub.status.idle":"2024-06-21T20:47:40.615470Z","shell.execute_reply.started":"2024-06-21T20:47:40.045979Z","shell.execute_reply":"2024-06-21T20:47:40.614666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Discriminator model","metadata":{}},{"cell_type":"code","source":"def Discriminator():\n    model = tf.keras.models.Sequential()\n    model.add(tf.keras.layers.Input((SIZE, SIZE, 3)))\n    model.add(tf.keras.layers.Conv2D(128,4, strides=2, padding='same',kernel_initializer='he_normal', use_bias=False))\n    model.add(tf.keras.layers.BatchNormalization())\n    model.add(tf.keras.layers.LeakyReLU())\n    model.add(tf.keras.layers.Conv2D(128,4, strides=2, padding='same',kernel_initializer='he_normal', use_bias=False))\n    model.add(tf.keras.layers.BatchNormalization())\n    model.add(tf.keras.layers.LeakyReLU())\n    model.add(tf.keras.layers.Conv2D(256,4, strides=2, padding='same',kernel_initializer='he_normal', use_bias=False))\n    model.add(tf.keras.layers.BatchNormalization())\n    model.add(tf.keras.layers.LeakyReLU())\n    model.add(tf.keras.layers.Conv2D(256,4, strides=2, padding='same',kernel_initializer='he_normal', use_bias=False))\n    model.add(tf.keras.layers.BatchNormalization())\n    model.add(tf.keras.layers.LeakyReLU())\n    model.add(tf.keras.layers.Conv2D(512,4, strides=2, padding='same',kernel_initializer='he_normal', use_bias=False))\n    model.add(tf.keras.layers.LeakyReLU())\n    model.add(tf.keras.layers.Flatten())\n    model.add(tf.keras.layers.Dense(1,activation = 'sigmoid'))\n    return model\n  \n","metadata":{"execution":{"iopub.status.busy":"2024-06-21T20:47:40.616563Z","iopub.execute_input":"2024-06-21T20:47:40.616836Z","iopub.status.idle":"2024-06-21T20:47:40.628814Z","shell.execute_reply.started":"2024-06-21T20:47:40.616810Z","shell.execute_reply":"2024-06-21T20:47:40.627477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"discriminator = Discriminator()\ndiscriminator.summary()","metadata":{"execution":{"iopub.status.busy":"2024-06-21T20:47:40.630192Z","iopub.execute_input":"2024-06-21T20:47:40.630627Z","iopub.status.idle":"2024-06-21T20:47:40.734258Z","shell.execute_reply.started":"2024-06-21T20:47:40.630543Z","shell.execute_reply":"2024-06-21T20:47:40.733523Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Plotting image generated by generator before training","metadata":{}},{"cell_type":"code","source":"noise = np.random.normal(-1,1,(1,100))\nimg = generator(noise)\nplt.imshow(img[0,:,:,0])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-06-21T20:47:40.735596Z","iopub.execute_input":"2024-06-21T20:47:40.735983Z","iopub.status.idle":"2024-06-21T20:47:43.782136Z","shell.execute_reply.started":"2024-06-21T20:47:40.735946Z","shell.execute_reply":"2024-06-21T20:47:43.781317Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Defining loss function and optimizer ","metadata":{}},{"cell_type":"code","source":"optimizer = tf.keras.optimizers.RMSprop(\n        lr=.0001,\n        clipvalue=1.0,\n        decay=1e-8\n    )\ncross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits = True)","metadata":{"execution":{"iopub.status.busy":"2024-06-21T20:47:43.784913Z","iopub.execute_input":"2024-06-21T20:47:43.785233Z","iopub.status.idle":"2024-06-21T20:47:43.790385Z","shell.execute_reply.started":"2024-06-21T20:47:43.785204Z","shell.execute_reply":"2024-06-21T20:47:43.789410Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def gen_loss(fake_output):\n    return cross_entropy(tf.ones_like(fake_output),fake_output)\ndef disc_loss(fake_output, real_output):\n    fake_loss = cross_entropy(tf.zeros_like(fake_output),fake_output)\n    real_loss = cross_entropy(tf.ones_like(real_output),real_output)\n    return fake_loss + real_loss","metadata":{"execution":{"iopub.status.busy":"2024-06-21T20:47:43.791995Z","iopub.execute_input":"2024-06-21T20:47:43.792352Z","iopub.status.idle":"2024-06-21T20:47:43.801140Z","shell.execute_reply.started":"2024-06-21T20:47:43.792316Z","shell.execute_reply":"2024-06-21T20:47:43.800327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Defining training steps","metadata":{}},{"cell_type":"code","source":"def train_steps(images):\n    noise = np.random.normal(0,1,(batch_size,latent_dim))\n    with tf.GradientTape() as gen_tape , tf.GradientTape() as disc_tape:\n        gen_images = generator(noise)\n        fake_output = discriminator(gen_images)\n        real_output = discriminator(images)\n        \n        generator_loss = gen_loss(fake_output)\n        discriminator_loss = disc_loss(fake_output, real_output)\n        \n        \n    gradient_of_generator = gen_tape.gradient(generator_loss, generator.trainable_variables)    \n    gradient_of_discriminator = disc_tape.gradient(discriminator_loss, discriminator.trainable_variables)\n    \n    optimizer.apply_gradients(zip(gradient_of_generator,generator.trainable_variables))\n    optimizer.apply_gradients(zip(gradient_of_discriminator, discriminator.trainable_variables))\n    \n    loss = {'gen loss':generator_loss,\n           'disc loss': discriminator_loss}\n    return loss","metadata":{"execution":{"iopub.status.busy":"2024-06-21T20:47:43.802521Z","iopub.execute_input":"2024-06-21T20:47:43.802994Z","iopub.status.idle":"2024-06-21T20:47:43.811194Z","shell.execute_reply.started":"2024-06-21T20:47:43.802955Z","shell.execute_reply":"2024-06-21T20:47:43.810329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Function to plot generated images\n","metadata":{}},{"cell_type":"code","source":"def plot_gen_images(square = 5, epochs = 0, save = False):\n    plt.figure(figsize = (10,10))\n    for i in range(square * square):\n        if epochs != 0:    \n            if(i == square //2):\n                plt.title(\"Generated Image at Epoch:{}\\n\".format(epochs), fontsize = 32, color = 'black')\n        plt.subplot(square, square, i+1)\n        noise = np.random.normal(0,1,(1,latent_dim))\n        img = generator(noise)\n        plt.imshow(np.clip((img[0,...]+1)/2, 0, 1))\n    \n        plt.xticks([])\n        plt.yticks([])\n        plt.grid()\n    if save:\n        plt.tight_layout()\n        plt.savefig('/kaggle/working/Epoch_{0}.png'.format(epochs), bbox_inches='tight')","metadata":{"execution":{"iopub.status.busy":"2024-06-21T20:47:43.812165Z","iopub.execute_input":"2024-06-21T20:47:43.812438Z","iopub.status.idle":"2024-06-21T20:47:43.824354Z","shell.execute_reply.started":"2024-06-21T20:47:43.812412Z","shell.execute_reply":"2024-06-21T20:47:43.823580Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Function to calculate Inception Score (IS)","metadata":{}},{"cell_type":"code","source":"def calculate_inception_score(images, n_split=10, eps=1E-16):\n    images_resized = np.array([resize(image, (299, 299, 3), anti_aliasing=True) for image in images])\n    images_resized = preprocess_input(images_resized)\n\n    inception_model = InceptionV3(include_top=False, pooling='avg')\n\n    preds = inception_model.predict(images_resized)\n\n    scores = []\n    for i in range(n_split):\n        part = preds[i * preds.shape[0] // n_split:(i + 1) * preds.shape[0] // n_split, :]\n        kl = part * (np.log(part + eps) - np.log(np.expand_dims(np.mean(part, 0), 0) + eps))\n        kl = np.mean(np.sum(kl, 1))\n        scores.append(np.exp(kl))\n\n    return np.mean(scores), np.std(scores)","metadata":{"execution":{"iopub.status.busy":"2024-06-21T20:47:43.825357Z","iopub.execute_input":"2024-06-21T20:47:43.825631Z","iopub.status.idle":"2024-06-21T20:47:43.833747Z","shell.execute_reply.started":"2024-06-21T20:47:43.825605Z","shell.execute_reply":"2024-06-21T20:47:43.833122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Function to calculate Fréchet Inception Distance (FID)","metadata":{}},{"cell_type":"code","source":"def calculate_fid(real_images, generated_images):\n    real_images_resized = np.array([resize(image, (299, 299, 3), anti_aliasing=True) for image in real_images])\n    generated_images_resized = np.array([resize(image, (299, 299, 3), anti_aliasing=True) for image in generated_images])\n    real_images_resized = preprocess_input(real_images_resized)\n    generated_images_resized = preprocess_input(generated_images_resized)\n\n    inception_model = InceptionV3(include_top=False, pooling='avg')\n\n    real_embeddings = inception_model.predict(real_images_resized)\n    generated_embeddings = inception_model.predict(generated_images_resized)\n\n    mu_real, sigma_real = np.mean(real_embeddings, axis=0), np.cov(real_embeddings, rowvar=False)\n    mu_generated, sigma_generated = np.mean(generated_embeddings, axis=0), np.cov(generated_embeddings, rowvar=False)\n\n    diff = mu_real - mu_generated\n    covmean = sqrtm(sigma_real.dot(sigma_generated))\n    if np.iscomplexobj(covmean):\n        covmean = covmean.real\n    fid = diff.dot(diff) + np.trace(sigma_real + sigma_generated - 2 * covmean)\n\n    return fid","metadata":{"execution":{"iopub.status.busy":"2024-06-21T20:47:43.835199Z","iopub.execute_input":"2024-06-21T20:47:43.835552Z","iopub.status.idle":"2024-06-21T20:47:43.846299Z","shell.execute_reply.started":"2024-06-21T20:47:43.835518Z","shell.execute_reply":"2024-06-21T20:47:43.845502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Function to train the model","metadata":{}},{"cell_type":"code","source":"import time\ndef train(epochs,dataset):\n    \n    for epoch in range(epochs):\n        start = time.time()\n        print(\"\\nEpoch : {}\".format(epoch + 1))\n        for images in dataset:\n            loss = train_steps(images)\n        print(\" Time:{}\".format(np.round(time.time() - start),2)) \n        print(\"Generator Loss: {} Discriminator Loss: {}\".format(loss['gen loss'],loss['disc loss']))\n        \n        num_images = 1000\n        gen_images = []\n        for _ in range(num_images // batch_size):\n            noise = np.random.normal(0, 1, (batch_size, latent_dim))\n            gen_imgs = generator(noise, training=False)\n            gen_images.append(gen_imgs.numpy())\n        gen_images = np.vstack(gen_images)\n\n        is_mean, is_std = calculate_inception_score(gen_images)\n        print(\"Inception Score - Mean: {}, Std: {}\".format(is_mean, is_std))\n\n        fid_score = calculate_fid(np.array(images[:num_images]), gen_images)\n        print(\"FID Score:\", fid_score)\n        \n        plot_gen_images(5, epoch, True)","metadata":{"execution":{"iopub.status.busy":"2024-06-21T20:47:43.847401Z","iopub.execute_input":"2024-06-21T20:47:43.847753Z","iopub.status.idle":"2024-06-21T20:47:43.856429Z","shell.execute_reply.started":"2024-06-21T20:47:43.847715Z","shell.execute_reply":"2024-06-21T20:47:43.855599Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training","metadata":{}},{"cell_type":"code","source":"train(20,dataset)","metadata":{"execution":{"iopub.status.busy":"2024-06-21T20:47:43.857514Z","iopub.execute_input":"2024-06-21T20:47:43.857841Z","iopub.status.idle":"2024-06-21T22:47:21.203740Z","shell.execute_reply.started":"2024-06-21T20:47:43.857808Z","shell.execute_reply":"2024-06-21T22:47:21.202819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Showing Generated Images (Output)\n","metadata":{}},{"cell_type":"code","source":"plot_gen_images(1)","metadata":{"execution":{"iopub.status.busy":"2024-06-21T22:47:21.205193Z","iopub.execute_input":"2024-06-21T22:47:21.205486Z","iopub.status.idle":"2024-06-21T22:47:21.315163Z","shell.execute_reply.started":"2024-06-21T22:47:21.205458Z","shell.execute_reply":"2024-06-21T22:47:21.314244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_gen_images(2)","metadata":{"execution":{"iopub.status.busy":"2024-06-21T22:47:21.316629Z","iopub.execute_input":"2024-06-21T22:47:21.317014Z","iopub.status.idle":"2024-06-21T22:47:21.778809Z","shell.execute_reply.started":"2024-06-21T22:47:21.316974Z","shell.execute_reply":"2024-06-21T22:47:21.778093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_gen_images(5)","metadata":{"execution":{"iopub.status.busy":"2024-06-21T22:47:21.779913Z","iopub.execute_input":"2024-06-21T22:47:21.780174Z","iopub.status.idle":"2024-06-21T22:47:23.190129Z","shell.execute_reply.started":"2024-06-21T22:47:21.780148Z","shell.execute_reply":"2024-06-21T22:47:23.189190Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_gen_images(10)","metadata":{"execution":{"iopub.status.busy":"2024-06-21T22:47:23.191470Z","iopub.execute_input":"2024-06-21T22:47:23.191819Z","iopub.status.idle":"2024-06-21T22:47:30.083006Z","shell.execute_reply.started":"2024-06-21T22:47:23.191769Z","shell.execute_reply":"2024-06-21T22:47:30.082191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Saving the model weights","metadata":{}},{"cell_type":"code","source":"generator.save('generator.h5')\ndiscriminator.save(\"discriminator.h5\")","metadata":{"execution":{"iopub.status.busy":"2024-06-21T22:47:30.084288Z","iopub.execute_input":"2024-06-21T22:47:30.084589Z","iopub.status.idle":"2024-06-21T22:47:30.289646Z","shell.execute_reply.started":"2024-06-21T22:47:30.084558Z","shell.execute_reply":"2024-06-21T22:47:30.288637Z"},"trusted":true},"execution_count":null,"outputs":[]}]}